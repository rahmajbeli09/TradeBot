# Analyse LLM avec Gemini - ChatbotNaSoft

## ğŸ¯ Objectif

Ce module implÃ©mente l'analyse dynamique des lignes anonymisÃ©es avec le LLM Gemini-1.5-Flash pour extraire la signification des champs et prÃ©parer les mappings pour le stockage MongoDB.

## ğŸ“ Structure des fichiers crÃ©Ã©s

```
src/main/java/com/example/chatbotnasoft/
â”œâ”€â”€ dto/
â”‚   â”œâ”€â”€ FieldMapping.java                 # Mapping des champs par msg-type
â”‚   â””â”€â”€ LLMAnalysisResult.java          # RÃ©sultat complet de l'analyse LLM
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ GeminiProperties.java            # Configuration Gemini
â”‚   â””â”€â”€ LLMConfiguration.java          # Configuration RestTemplate et ObjectMapper
â”œâ”€â”€ service/
â”‚   â””â”€â”€ LLMService.java               # Service principal d'analyse LLM
â””â”€â”€ controller/
    â””â”€â”€ LLMController.java            # API pour l'analyse LLM

src/test/java/com/example/chatbotnasoft/
â””â”€â”€ LLMServiceTest.java               # Tests unitaires complets
```

## ğŸ”§ Configuration Gemini

### application.yml
```yaml
gemini:
  api-key: AIzaSyDffpeEpLaHTsnPZlBiW5eXYrOw5DGyhxc
  model: gemini-1.5-flash
  base-url: https://generativelanguage.googleapis.com/v1beta
  timeout-seconds: 30
  max-retries: 3
  temperature: 0.1
  max-tokens: 1024
```

## ğŸ¤– Processus d'Analyse LLM

1. **SÃ©lection** : Uniquement les msg-types inconnus sont envoyÃ©s au LLM
2. **Analyse** : Gemini analyse dynamiquement chaque champ selon le msg-type
3. **Extraction** : Parsing du JSON rÃ©ponse pour obtenir les significations
4. **Mapping** : CrÃ©ation des structures prÃªtes pour MongoDB
5. **Validation** : VÃ©rification de la cohÃ©rence des rÃ©sultats

## ğŸ“Š Objets crÃ©Ã©s

### FieldMapping
```java
public class FieldMapping {
    private String msgType;                    // Type de message
    private Map<String, String> mapping;       // Champ -> Signification
    private LocalDateTime analyzedAt;           // Timestamp d'analyse
    private String originalLine;                // Ligne originale
    private String anonymizedLine;              // Ligne anonymisÃ©e
    private int fieldCount;                    // Nombre de champs
}
```

### LLMAnalysisResult
```java
public class LLMAnalysisResult {
    private Map<String, List<FieldMapping>> resultsByMsgType;  // RÃ©sultats par msg-type
    private List<String> analysisErrors;                        // Erreurs d'analyse
    private int totalLinesAnalyzed;                            // Total lignes analysÃ©es
    private int successfulAnalyses;                               // Analyses rÃ©ussies
    private int failedAnalyses;                                   // Analyses Ã©chouÃ©es
    private double successRate;                                    // Taux de succÃ¨s
}
```

## ğŸš€ API REST

### Analyser un fichier complet
```bash
POST http://localhost:8080/api/llm/analyze-file/FEED_TEST_LLM.txt
```

**RÃ©ponse exemple :**
```json
{
  "success": true,
  "fileName": "FEED_TEST_LLM.txt",
  "totalLines": 5,
  "unknownMsgTypes": ["99", "88"],
  "knownMsgTypes": ["20"],
  "analyzedLines": 4,
  "successfulAnalyses": 4,
  "failedAnalyses": 0,
  "successRate": 100.0,
  "fieldMappings": {
    "99": [
      {
        "msgType": "99",
        "mapping": {
          "Champ 1": "Identifiant de transaction",
          "Champ 2": "Code de message",
          "Champ 3": "Date de traitement",
          "Champ 4": "DonnÃ©es sensibles 1",
          "Champ 5": "DonnÃ©es sensibles 2",
          "Champ 6": "DonnÃ©es sensibles 3"
        },
        "fieldCount": 6
      }
    ],
    "88": [
      {
        "msgType": "88", 
        "mapping": {
          "Champ 1": "RÃ©fÃ©rence client",
          "Champ 2": "Type d'opÃ©ration",
          "Champ 3": "Montant",
          "Champ 4": "Devise",
          "Champ 5": "Statut",
          "Champ 6": "Timestamp",
          "Champ 7": "Code validation"
        },
        "fieldCount": 7
      }
    ]
  }
}
```

### Analyser une ligne individuelle
```bash
POST http://localhost:8080/api/llm/analyze-line
?anonymizedLine=077;99;23012025;xxxxx;xxxxx;xxxxx&msgType=99
```

### Tester la connexion Gemini
```bash
GET http://localhost:8080/api/llm/test-connection
```

## ğŸ§ª Tests

### ExÃ©cuter les tests unitaires
```bash
mvn test -Dtest=LLMServiceTest
```

### Test manuel rapide
```bash
# 1. CrÃ©er un fichier de test avec msg-types inconnus
echo -e "077;99;23012025;XXXX;YYYY;ZZZZ\n078;88;23012025;field3;field4" > input/feeds/FEED_TEST_LLM.txt

# 2. Analyser le fichier
curl -u user:<password> -X POST http://localhost:8080/api/llm/analyze-file/FEED_TEST_LLM.txt

# 3. Tester la connexion
curl -u user:<password] http://localhost:8080/api/llm/test-connection
```

## ğŸ“ˆ Logs gÃ©nÃ©rÃ©s

```bash
INFO  - ğŸ¤– DÃ©but de l'analyse LLM pour 2 msg-types
INFO  - ğŸ” Analyse du msg-type '99' avec 2 lignes
DEBUG - ğŸ” RÃ©ponse Gemini brute: {"Champ 1": "Identifiant", "Champ 2": "Type", ...}
DEBUG - ğŸ“‹ Mapping extrait: {Champ 1=Identifiant, Champ 2=Type, ...}
INFO  - âœ… Analyse terminÃ©e pour msg-type '99': 2 mappings crÃ©Ã©s
INFO  - ğŸ“Š RÃ©sumÃ© de l'analyse LLM:
INFO  -    â€¢ Lignes totales analysÃ©es: 4
INFO  -    â€¢ Analyses rÃ©ussies: 4
INFO  -    â€¢ Analyses Ã©chouÃ©es: 0
INFO  -    â€¢ Msg-types traitÃ©s: 2
INFO  -    â€¢ Taux de succÃ¨s: 100.0%
INFO  -    â€¢ Msg-type '99': 2 mappings
INFO  -    â€¢ Msg-type '88': 2 mappings
INFO  - ğŸ§  Analyse LLM terminÃ©e: 4 lignes analysÃ©es avec 100.0% de succÃ¨s
INFO  - ğŸ’¾ PrÃªt pour stockage MongoDB: 4 mappings crÃ©Ã©s
```

## ğŸ” Prompt Gemini

Le prompt envoyÃ© Ã  Gemini pour chaque ligne :

```
Analyse cette ligne de feed anonymisÃ©e :
Ligne : 077;99;23012025;xxxxx;xxxxx;xxxxx

- DÃ©tecte dynamiquement la signification de chaque champ en fonction du msg-type
- Fournis le rÃ©sultat sous **format JSON**, avec :
  {
    "Champ 1": "Signification",
    "Champ 2": "Signification", 
    "Champ 3": "Signification",
    ...
  }
- **Important** : Chaque ligne peut avoir un nombre diffÃ©rent de champs. Ne pas utiliser l'exemple comme modÃ¨le pour toutes les lignes.
```

## âš¡ Performance

- **ParallÃ©lisation** : Analyse simultanÃ©e des msg-types avec CompletableFuture
- **Mise en cache** : MÃªme mapping appliquÃ© Ã  toutes les lignes du mÃªme msg-type
- **Gestion d'erreurs** : Retry automatique et gestion des timeouts
- **Validation JSON** : Parsing robuste avec extraction du JSON dans la rÃ©ponse

## ğŸ”„ IntÃ©gration Pipeline

Le systÃ¨me s'intÃ¨gre parfaitement dans le pipeline existant :

1. **FileWatcherService** â†’ DÃ©tection des fichiers
2. **FileStabilizationService** â†’ Stabilisation (5 secondes)
3. **FileReadingService** â†’ Lecture des lignes
4. **FeedParsingService** â†’ Regroupement par msg-type
5. **FeedDetectionService** â†’ VÃ©rification MongoDB
6. **AnonymizationService** â†’ Anonymisation si inconnu
7. **LLMService** â†’ **Analyse dynamique des champs** â­
8. **Prochaines Ã©tapes** â†’ Stockage MongoDB, Mapping final

## ğŸ“‹ Prochaines Ã©tapes

Une fois les mappings LLM crÃ©Ã©s, les prochaines Ã©tapes incluront :
1. **Stockage MongoDB** : Persistance des FieldMapping dans la collection appropriÃ©e
2. **Validation mÃ©tier** : VÃ©rification des rÃ¨gles par msg-type
3. **Mapping final** : Transformation vers le format de production
4. **Monitoring** : Tableaux de bord et alertes
5. **Optimisation** : Cache des mappings pour les msg-types rÃ©currents
